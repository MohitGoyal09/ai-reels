# AI-Reels: Fashion Analysis Pipeline

A computer vision and NLP pipeline that analyzes fashion videos to detect fashion items, match them to product catalogs, and classify fashion vibes.

## ğŸŒŸ Features

- **Fashion Item Detection**: Uses YOLOS Fashionpedia to detect clothing items and accessories in videos
- **Product Matching**: Matches detected items to a product catalog using CLIP embeddings and FAISS
- **Fashion Vibe Classification**: Detects fashion vibes (Coquette, Clean Girl, Y2K, etc.) using zero-shot text classification
- **Color Recognition**: Identifies dominant colors in detected fashion items
- **Video Frame Analysis**: Extracts key frames from videos using scene change detection
- **JSON Output**: Generates structured JSON output for each video with detected vibes and matched products

## ğŸ“‹ Requirements

- Python 3.9+
- PyTorch
- Transformers
- OpenCV
- FAISS
- PIL
- Pandas
- HuggingFace models

## ğŸš€ Quick Start

1. **Clone the repository**

   ```
   git clone https://github.com/MohitGoyal09/ai-reels.git
   cd ai-reels
   ```

2. **Install dependencies**

   ```
   pip install -r requirements.txt
   ```

3. **Prepare your data structure**

   ```
   data/
   â”œâ”€â”€ videos/             # Place your .mp4 video files here
   â”œâ”€â”€ captions/           # Place [video_id].txt files with captions here
   â”œâ”€â”€ metadata_json/      # Place [video_id].json files with metadata here
   â”œâ”€â”€ product_data.csv    # Product catalog with metadata
   â””â”€â”€ vibeslist.json      # List of fashion vibes to detect
   
   models/precomputed/
   â”œâ”€â”€ catalog.index       # FAISS index of product embeddings
   â””â”€â”€ product_ids.csv     # Mapping of FAISS indices to product IDs
   ```

4. **Run the pipeline**

   ```
   python scripts/process_videos.py
   ```

5. **Check results**

   ```
   output/
   â””â”€â”€ [video_id].json     # Results for each processed video
   ```

## ğŸ“Š Output Format

Each processed video generates a JSON file with the following structure:

```json
{
  "video_id": "2025-05-22_08-25-12_UTC",
  "vibes": ["Boho", "Clean Girl"],
  "products": [
    {
      "type": "dress",
      "matched_product_id": "12345",
      "product_name": "Floral Summer Dress",
      "color": "Blue, White",
      "print_pattern": "Floral",
      "match_type": "similar",
      "detection_confidence": 0.9231,
      "matching_similarity": 0.8765,
      "frame_number": 120
    },
    // More products...
  ]
}
```

## ğŸ§  Architecture

The system consists of several interconnected components:

1. **Video Processor**: Extracts keyframes from videos based on scene change detection
2. **Fashion Detector**: Detects fashion items using YOLOS Fashionpedia model
3. **Product Matcher**: Matches detected items to a catalog using CLIP embeddings and FAISS
4. **Vibe Classifier**: Classifies fashion vibes using zero-shot classification
5. **Main Pipeline**: Orchestrates the entire process and generates JSON output

## ğŸ“ Project Structure

```
ai-reels/
â”œâ”€â”€ data/                  # Data directory
â”œâ”€â”€ models/                # Model implementations
â”‚   â”œâ”€â”€ fashion_detector_auto.py
â”‚   â”œâ”€â”€ product_matcher.py
â”‚   â”œâ”€â”€ vibe_classifier_hf_zeroshot.py
â”‚   â””â”€â”€ precomputed/       # Pre-computed model files
â”œâ”€â”€ output/                # Output JSON files
â”œâ”€â”€ scripts/               # Main scripts
â”‚   â””â”€â”€ process_videos.py  # Main pipeline script
â”œâ”€â”€ utils/                 # Utility functions
â”‚   â”œâ”€â”€ text_cleaner.py
â”‚   â””â”€â”€ video_processor.py
â””â”€â”€ README.md              # This file
```

## âš™ï¸ Configuration

The main configuration parameters are defined at the top of `scripts/process_videos.py`:

- `ZS_VIBE_CONFIDENCE_THRESHOLD`: Confidence threshold for vibe classification (default: 0.50)
- `FASHION_DETECTOR_CONFIDENCE`: Confidence threshold for fashion item detection (default: 0.40)
- Various file paths for input/output data

## ğŸ”§ Advanced Usage

### Parallel Processing

For large batches of videos, you can implement parallel processing by modifying the main loop in `process_videos.py`:

```python
with concurrent.futures.ProcessPoolExecutor(max_workers=4) as executor:
    futures = [executor.submit(process_single_video, ...) for video_p_obj in all_video_file_paths]
    for future in concurrent.futures.as_completed(futures):
        result_json_data = future.result()
        # Save result...
```

### Custom Fashion Categories

You can modify the `MAIN_FASHION_CATEGORIES` and `SECONDARY_FASHION_CATEGORIES` lists in `process_videos.py` to focus on specific fashion items.

### Customizing Vibe Detection

Edit the vibe keywords in the `vibe_keywords` dictionary in `process_single_video()` to enhance vibe detection for specific fashion styles.

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## ğŸ“œ License

This project is licensed under the MIT License - see the LICENSE file for details.

